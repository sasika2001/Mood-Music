<h1>ğŸµ Mood-Based Music Recommendation System</h1>

<h2>ğŸ©µ Project Overview</h2>
<p>The <strong>Mood-Based Music Recommendation System</strong> recommends songs based on the userâ€™s mood.  
It takes input as a user-selected mood or a facial expression image, processes it through a machine learning model, and returns a personalized playlist or song suggestions.</p>

<blockquote>
ğŸ’¡ <em>Example:</em><br>
If the user is feeling <strong>happy</strong>, the system may recommend upbeat songs.  
If the user is <strong>sad</strong>, it may suggest calming or soothing music.
</blockquote>

<h2>ğŸ¯ Key Features</h2>
<ul>
  <li>âœ… Detects user mood from facial expression images or manual selection</li>
  <li>âœ… Uses ML/Deep Learning for mood classification</li>
  <li>âœ… Provides personalized music recommendations</li>
  <li>âœ… Backend implemented with FastAPI</li>
  <li>âœ… Simple and user-friendly frontend with HTML</li>
  <li>âœ… Easily extendable for new moods or music datasets</li>
</ul>

<h2>ğŸ§  System Workflow</h2>
<ol>
  <li>User provides input:
    <ul>
      <li>Upload a facial expression image (<code>preprocess_image.py</code>)</li>
      <li>Or manually select mood from the frontend</li>
    </ul>
  </li>
  <li>Backend processes the input:
    <ul>
      <li>Preprocessing using <code>preprocess_image.py</code></li>
      <li>Mood prediction using trained model (<code>train_model.py</code>)</li>
      <li>Music recommendation using <code>music_recommender.py</code></li>
    </ul>
  </li>
  <li>Response sent to frontend:
    <ul>
      <li>Recommended songs displayed in <code>index.html</code></li>
    </ul>
  </li>
</ol>

<h2>âš™ï¸ Technologies Used</h2>
<table>
<tr><th>Category</th><th>Tools / Libraries</th></tr>
<tr><td>Programming Language</td><td>Python 3.10</td></tr>
<tr><td>Backend Framework</td><td>FastAPI</td></tr>
<tr><td>Frontend</td><td>HTML, CSS</td></tr>
<tr><td>Deep Learning / ML</td><td>TensorFlow, Keras, scikit-learn</td></tr>
<tr><td>Image Processing</td><td>OpenCV, PIL</td></tr>
<tr><td>Data Handling</td><td>NumPy, Pandas</td></tr>
<tr><td>Utilities</td><td>utils.py for helper functions</td></tr>
<tr><td>IDE</td><td>VS Code</td></tr>
</table>

<h2>ğŸ“ Project Folder Structure</h2>
<pre>
MoodMusicSystem/
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py               # FastAPI main server
â”‚       â”œâ”€â”€ models.py             # Data models / schemas
â”‚       â”œâ”€â”€ music_recommender.py  # Logic to recommend songs
â”‚       â”œâ”€â”€ preprocess_image.py   # Image preprocessing
â”‚       â”œâ”€â”€ train_model.py        # Train mood classification model
â”‚       â””â”€â”€ utils.py              # Helper functions
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                # Frontend interface
â”œâ”€â”€ dataset/                       # Mood-labeled music / images
â”œâ”€â”€ requirements.txt               # Dependencies list
â””â”€â”€ README.md                      # Project documentation
</pre>

<h2>ğŸ“¦ Installation & Setup (Windows)</h2>

<h3>1ï¸âƒ£ Clone the Project</h3>
<pre><code>git clone https://github.com/yourusername/mood-music-recommender.git
cd mood-music-recommender
</code></pre>

<h3>2ï¸âƒ£ Open Command Prompt or PowerShell</h3>
<p>Press <strong>Windows + R</strong>, type <code>cmd</code>, and press Enter.  
Navigate to the project folder:</p>
<pre><code>cd C:\Users\<YourUserName>\Desktop\MoodMusicSystem
</code></pre>

<h3>3ï¸âƒ£ Create a Virtual Environment</h3>
<pre><code>python -m venv venv
</code></pre>

<h3>4ï¸âƒ£ Activate the Virtual Environment</h3>
<pre><code>venv\Scripts\activate
</code></pre>
<p>After activation, you should see:</p>
<pre><code>(venv) C:\Users\YourName\Desktop\MoodMusicSystem&gt;
</code></pre>

<h3>5ï¸âƒ£ Install Required Libraries</h3>
<p>If <code>requirements.txt</code> exists:</p>
<pre><code>pip install -r requirements.txt
</code></pre>
<p>If not, install manually:</p>
<pre><code>pip install fastapi uvicorn tensorflow opencv-python numpy pandas
</code></pre>

---

<h2>â–¶ï¸ How to Run the Project</h2>

<h3>ğŸ–¥ï¸ Step 1 â€” Start Backend Server</h3>
<pre><code>cd backend
uvicorn app.main:app --reload
</code></pre>
<p>This starts the FastAPI backend at <code>http://127.0.0.1:8000</code>.</p>

<h3>ğŸ–¥ï¸ Step 2 â€” Open Frontend</h3>
<p>Open <code>frontend/index.html</code> in your web browser. The frontend communicates with the backend API to:</p>
<ul>
  <li>Send user mood selection or uploaded image</li>
  <li>Receive recommended music</li>
  <li>Display songs on the page</li>
</ul>

---

<h2>ğŸ§© Example Output</h2>
<p><strong>Input:</strong> Upload an image of your face or select "Happy" mood from dropdown.</p>

<p><strong>Output:</strong></p>
<ul>
  <li>Detected mood: <strong>Happy</strong></li>
  <li>Recommended songs:</li>
  <ul>
    <li>"Happy" by Pharrell Williams</li>
    <li>"Can't Stop the Feeling!" by Justin Timberlake</li>
    <li>"Good Feeling" by Flo Rida</li>
  </ul>
</ul>

---

<h2>ğŸš€ Future Improvements</h2>
<ul>
  <li>Train on larger, diverse datasets for more accurate mood detection</li>
  <li>Add support for additional moods (relaxed, angry, energetic)</li>
  <li>Integrate Spotify / YouTube APIs for live music recommendations</li>
  <li>Mobile-friendly frontend using React Native or Flutter</li>
</ul>

---

<h2>ğŸ‘©â€ğŸ’» Author</h2>
<p><strong>Sasika Sewmini</strong><br>
University of Moratuwa â€” 3rd Year Undergraduate<br>
<a href="https://www.linkedin.com/in/sasika-sewmini-dp-829535351">LinkedIn Profile</a><br>
Email: <a href="mailto:dpsasikapeiris@gmail.com">dpsasikapeiris@gmail.com</a></p>

<p>â­ If you like this project, give it a star on GitHub!</p>
